{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import xlrd\n",
    "\n",
    "model_inputs = np.array([])\n",
    "model_outputs = np.array([])\n",
    "test_inputs = np.array([])\n",
    "test_outputs = np.array([])\n",
    "test_score = np.array([])\n",
    "model = tf.keras.models.Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(model_first_row, model_final_row, test_first_row, test_final_row):\n",
    "\n",
    "    global model_inputs, model_outputs, test_inputs, test_outputs, test_score\n",
    "    # Load Full dataset (masterData)\n",
    "    ExcelFileName= 'datafull.xls'\n",
    "    workbook = xlrd.open_workbook(ExcelFileName)\n",
    "    worksheet = workbook.sheet_by_name(\"Data\") \n",
    "\n",
    "    # model_first_row = 2500\n",
    "    # model_final_row = 3500\n",
    "    # test_first_row = 3501 \n",
    "    # test_final_row = 3505\n",
    "\n",
    "    score_col = 27\n",
    "    first_col = 27\n",
    "    final_col = 58\n",
    "\n",
    "    model_inputs = np.zeros([model_final_row - model_first_row, final_col - first_col])\n",
    "    model_outputs = np.zeros([model_final_row - model_first_row])\n",
    "\n",
    "    for row in range(model_first_row - 1, model_final_row - 1):\n",
    "        cell_value = worksheet.cell_value(row, first_col)\n",
    "        model_outputs[row - model_first_row + 1] = cell_value\n",
    "\n",
    "        for col in range(first_col, final_col):\n",
    "            cell_value = worksheet.cell_value(row, col + 1)\n",
    "            model_inputs[row - model_first_row + 1, col - first_col] = cell_value\n",
    "\n",
    "\n",
    "    test_inputs = np.zeros([test_final_row - test_first_row, final_col - first_col])\n",
    "    test_outputs = np.zeros([test_final_row - test_first_row])\n",
    "    test_score = np.zeros([test_final_row - test_first_row])\n",
    "\n",
    "    for row in range(test_first_row - 1, test_final_row - 1):\n",
    "        cell_value = worksheet.cell_value(row, first_col)\n",
    "        test_outputs[row - test_first_row + 1] = cell_value\n",
    "        cell_value = worksheet.cell_value(row, score_col)\n",
    "        test_score[row - test_first_row + 1] = cell_value\n",
    "\n",
    "        for col in range(first_col, final_col):\n",
    "            cell_value = worksheet.cell_value(row, col + 1)\n",
    "            test_inputs[row - test_first_row + 1, col - first_col] = cell_value\n",
    "\n",
    "def normalize(nparray):\n",
    "    nparray = nparray.transpose()\n",
    "    for row in range(np.size(nparray, 0) - 1):\n",
    "        nparray[row] = tf.keras.utils.normalize(nparray[row], axis=0)\n",
    "    nparray = nparray.transpose()\n",
    "    return nparray\n",
    "\n",
    "            \n",
    "def evaluate():\n",
    "    \n",
    "    global test_inputs, test_score, model\n",
    "    wrong = 0.0\n",
    "    right = 0.0\n",
    "    none = 0.0\n",
    "    results = []\n",
    "    for r in range(len(test_score) ):\n",
    "        predict = model.predict_classes(test_inputs[r:r+1])[0]\n",
    "        results.append(predict)\n",
    "        if ((predict==2 and test_score[r] > 0) or (predict==0 and test_score[r] < 0)):\n",
    "            right += abs(test_score[r])\n",
    "        if ((predict==2 and test_score[r] < 0) or (predict==0 and test_score[r] > 0)):\n",
    "            wrong += abs(test_score[r])\n",
    "        if (predict==1):\n",
    "            none += abs(test_score[r])\n",
    "    return wrong, right, none, results            \n",
    "\n",
    "\n",
    "def optimize(tries):\n",
    "\n",
    "    global model_inputs, model_outputs, model\n",
    "    wrong = right = none = 0.0\n",
    "    total_wrong = total_right = total_none = 0.0\n",
    "    res = list()\n",
    "\n",
    "    for t in range(tries):\n",
    "\n",
    "        model = tf.keras.models.Sequential()  # a basic feed-forward model\n",
    "        model.add(tf.keras.layers.Dense(64,  activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "        model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "        model.add(tf.keras.layers.Dense(3, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "\n",
    "        model.compile(optimizer='adam',  # Good default optimizer to start with\n",
    "                      loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
    "                      metrics=['accuracy'])  # what to track\n",
    "\n",
    "        model.fit(model_inputs, model_outputs, epochs=100, verbose=0)  # train the model\n",
    "\n",
    "        results = []\n",
    "        wrong, right, none, results = evaluate()\n",
    "        total_wrong += wrong\n",
    "        total_right += right\n",
    "        total_none += none\n",
    "        if (wrong + right == 0):\n",
    "            result = 0\n",
    "        else:\n",
    "            result = 100*(right/(right + wrong))\n",
    "        res.append(result)\n",
    "        for t in range(len(results)):\n",
    "            print(\"Projected Row:\", end = '')\n",
    "            print(projectedRow, end = ' ')\n",
    "            print(\"Result:\", end = '')\n",
    "            print(projectedRow + t, end = ' ')\n",
    "            print(results[t])\n",
    "\n",
    "    print(\"{p:6.2f}\".format(p=total_right), end = ' ')\n",
    "    print(\"{p:6.2f}\".format(p=total_wrong), end = ' ')\n",
    "    print(\"{p:6.2f}\".format(p=total_none), end = ' ')\n",
    "    return total_right, total_wrong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadData(1000,1500,1501,1550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected Row:1000 Result:1000 2\n",
      "Projected Row:1000 Result:1001 2\n",
      "Projected Row:1000 Result:1002 2\n",
      "Projected Row:1000 Result:1003 2\n",
      "Projected Row:1000 Result:1004 2\n",
      "Projected Row:1000 Result:1005 2\n",
      "Projected Row:1000 Result:1006 2\n",
      "Projected Row:1000 Result:1007 2\n",
      "Projected Row:1000 Result:1008 2\n",
      "Projected Row:1000 Result:1009 2\n",
      "  6.00   0.00   0.00 100.00%\n",
      "Projected Row:1001 Result:1001 2\n",
      "Projected Row:1001 Result:1002 2\n",
      "Projected Row:1001 Result:1003 2\n",
      "Projected Row:1001 Result:1004 2\n",
      "Projected Row:1001 Result:1005 2\n",
      "Projected Row:1001 Result:1006 2\n",
      "Projected Row:1001 Result:1007 2\n",
      "Projected Row:1001 Result:1008 2\n",
      "Projected Row:1001 Result:1009 2\n",
      "Projected Row:1001 Result:1010 2\n",
      "  6.00   0.00   0.00 100.00%\n",
      "Projected Row:1002 Result:1002 2\n",
      "Projected Row:1002 Result:1003 2\n",
      "Projected Row:1002 Result:1004 2\n",
      "Projected Row:1002 Result:1005 2\n",
      "Projected Row:1002 Result:1006 2\n",
      "Projected Row:1002 Result:1007 2\n",
      "Projected Row:1002 Result:1008 2\n",
      "Projected Row:1002 Result:1009 2\n",
      "Projected Row:1002 Result:1010 2\n",
      "Projected Row:1002 Result:1011 2\n",
      "  6.00   0.00   0.00 100.00%\n",
      "Projected Row:1003 Result:1003 2\n",
      "Projected Row:1003 Result:1004 2\n",
      "Projected Row:1003 Result:1005 2\n",
      "Projected Row:1003 Result:1006 2\n",
      "Projected Row:1003 Result:1007 2\n",
      "Projected Row:1003 Result:1008 2\n",
      "Projected Row:1003 Result:1009 2\n",
      "Projected Row:1003 Result:1010 2\n",
      "Projected Row:1003 Result:1011 2\n",
      "Projected Row:1003 Result:1012 2\n",
      "  4.00   0.00   0.00 100.00%\n",
      "Projected Row:1004 Result:1004 2\n",
      "Projected Row:1004 Result:1005 2\n",
      "Projected Row:1004 Result:1006 2\n",
      "Projected Row:1004 Result:1007 2\n",
      "Projected Row:1004 Result:1008 2\n",
      "Projected Row:1004 Result:1009 2\n",
      "Projected Row:1004 Result:1010 2\n",
      "Projected Row:1004 Result:1011 2\n",
      "Projected Row:1004 Result:1012 2\n",
      "Projected Row:1004 Result:1013 2\n",
      "  6.00   0.00   0.00 100.00%\n",
      "Projected Row:1005 Result:1005 2\n",
      "Projected Row:1005 Result:1006 2\n",
      "Projected Row:1005 Result:1007 2\n",
      "Projected Row:1005 Result:1008 2\n",
      "Projected Row:1005 Result:1009 2\n",
      "Projected Row:1005 Result:1010 2\n",
      "Projected Row:1005 Result:1011 2\n",
      "Projected Row:1005 Result:1012 2\n",
      "Projected Row:1005 Result:1013 2\n",
      "Projected Row:1005 Result:1014 2\n",
      "  8.00   0.00   0.00 100.00%\n",
      "Projected Row:1006 Result:1006 2\n",
      "Projected Row:1006 Result:1007 2\n",
      "Projected Row:1006 Result:1008 0\n",
      "Projected Row:1006 Result:1009 2\n",
      "Projected Row:1006 Result:1010 2\n",
      "Projected Row:1006 Result:1011 2\n",
      "Projected Row:1006 Result:1012 2\n",
      "Projected Row:1006 Result:1013 2\n",
      "Projected Row:1006 Result:1014 2\n",
      "Projected Row:1006 Result:1015 0\n",
      "  8.00   2.00   0.00  95.65%\n",
      "Projected Row:1007 Result:1007 2\n",
      "Projected Row:1007 Result:1008 2\n",
      "Projected Row:1007 Result:1009 2\n",
      "Projected Row:1007 Result:1010 2\n",
      "Projected Row:1007 Result:1011 2\n",
      "Projected Row:1007 Result:1012 2\n",
      "Projected Row:1007 Result:1013 2\n",
      "Projected Row:1007 Result:1014 2\n",
      "Projected Row:1007 Result:1015 2\n",
      "Projected Row:1007 Result:1016 2\n",
      " 12.00   0.00   0.00  96.55%\n",
      "Projected Row:1008 Result:1008 0\n",
      "Projected Row:1008 Result:1009 0\n",
      "Projected Row:1008 Result:1010 0\n",
      "Projected Row:1008 Result:1011 2\n",
      "Projected Row:1008 Result:1012 2\n",
      "Projected Row:1008 Result:1013 2\n",
      "Projected Row:1008 Result:1014 0\n",
      "Projected Row:1008 Result:1015 0\n",
      "Projected Row:1008 Result:1016 0\n",
      "Projected Row:1008 Result:1017 2\n",
      "  4.00   6.00   0.00  88.24%\n",
      "Projected Row:1009 Result:1009 2\n",
      "Projected Row:1009 Result:1010 2\n",
      "Projected Row:1009 Result:1011 2\n",
      "Projected Row:1009 Result:1012 2\n",
      "Projected Row:1009 Result:1013 2\n",
      "Projected Row:1009 Result:1014 2\n",
      "Projected Row:1009 Result:1015 2\n",
      "Projected Row:1009 Result:1016 2\n",
      "Projected Row:1009 Result:1017 2\n",
      "Projected Row:1009 Result:1018 2\n",
      " 12.00   0.00   0.00  90.00%\n",
      "Projected Row:1010 Result:1010 2\n",
      "Projected Row:1010 Result:1011 2\n",
      "Projected Row:1010 Result:1012 2\n",
      "Projected Row:1010 Result:1013 2\n",
      "Projected Row:1010 Result:1014 2\n",
      "Projected Row:1010 Result:1015 2\n",
      "Projected Row:1010 Result:1016 2\n",
      "Projected Row:1010 Result:1017 2\n",
      "Projected Row:1010 Result:1018 2\n",
      "Projected Row:1010 Result:1019 2\n",
      " 12.00   0.00   0.00  91.30%\n",
      "Projected Row:1011 Result:1011 2\n",
      "Projected Row:1011 Result:1012 2\n",
      "Projected Row:1011 Result:1013 2\n",
      "Projected Row:1011 Result:1014 2\n",
      "Projected Row:1011 Result:1015 2\n",
      "Projected Row:1011 Result:1016 2\n",
      "Projected Row:1011 Result:1017 2\n",
      "Projected Row:1011 Result:1018 2\n",
      "Projected Row:1011 Result:1019 2\n",
      "Projected Row:1011 Result:1020 2\n",
      " 14.00   0.00   0.00  92.45%\n",
      "Projected Row:1012 Result:1012 2\n",
      "Projected Row:1012 Result:1013 2\n",
      "Projected Row:1012 Result:1014 2\n",
      "Projected Row:1012 Result:1015 2\n",
      "Projected Row:1012 Result:1016 2\n",
      "Projected Row:1012 Result:1017 2\n",
      "Projected Row:1012 Result:1018 2\n",
      "Projected Row:1012 Result:1019 2\n",
      "Projected Row:1012 Result:1020 2\n",
      "Projected Row:1012 Result:1021 2\n",
      " 14.00   0.00   0.00  93.33%\n",
      "Projected Row:1013 Result:1013 2\n",
      "Projected Row:1013 Result:1014 0\n",
      "Projected Row:1013 Result:1015 2\n",
      "Projected Row:1013 Result:1016 0\n",
      "Projected Row:1013 Result:1017 2\n",
      "Projected Row:1013 Result:1018 2\n",
      "Projected Row:1013 Result:1019 2\n",
      "Projected Row:1013 Result:1020 2\n",
      "Projected Row:1013 Result:1021 2\n",
      "Projected Row:1013 Result:1022 2\n",
      " 12.00   4.00   0.00  91.18%\n",
      "Projected Row:1014 Result:1014 0\n",
      "Projected Row:1014 Result:1015 0\n",
      "Projected Row:1014 Result:1016 0\n",
      "Projected Row:1014 Result:1017 0\n",
      "Projected Row:1014 Result:1018 0\n",
      "Projected Row:1014 Result:1019 0\n",
      "Projected Row:1014 Result:1020 0\n",
      "Projected Row:1014 Result:1021 0\n",
      "Projected Row:1014 Result:1022 0\n",
      "Projected Row:1014 Result:1023 0\n",
      "  0.00  14.00   0.00  82.67%\n",
      "Projected Row:1015 Result:1015 0\n",
      "Projected Row:1015 Result:1016 0\n",
      "Projected Row:1015 Result:1017 2\n",
      "Projected Row:1015 Result:1018 2\n",
      "Projected Row:1015 Result:1019 2\n",
      "Projected Row:1015 Result:1020 2\n",
      "Projected Row:1015 Result:1021 2\n",
      "Projected Row:1015 Result:1022 2\n",
      "Projected Row:1015 Result:1023 2\n",
      "Projected Row:1015 Result:1024 2\n",
      " 10.00   4.00   0.00  81.71%\n",
      "Projected Row:1016 Result:1016 0\n",
      "Projected Row:1016 Result:1017 0\n",
      "Projected Row:1016 Result:1018 0\n",
      "Projected Row:1016 Result:1019 0\n",
      "Projected Row:1016 Result:1020 0\n",
      "Projected Row:1016 Result:1021 0\n",
      "Projected Row:1016 Result:1022 0\n",
      "Projected Row:1016 Result:1023 0\n",
      "Projected Row:1016 Result:1024 0\n",
      "Projected Row:1016 Result:1025 0\n",
      "  0.00  12.00   0.00  76.14%\n",
      "Projected Row:1017 Result:1017 2\n",
      "Projected Row:1017 Result:1018 2\n",
      "Projected Row:1017 Result:1019 2\n",
      "Projected Row:1017 Result:1020 2\n",
      "Projected Row:1017 Result:1021 2\n",
      "Projected Row:1017 Result:1022 2\n",
      "Projected Row:1017 Result:1023 2\n",
      "Projected Row:1017 Result:1024 2\n",
      "Projected Row:1017 Result:1025 2\n",
      "Projected Row:1017 Result:1026 2\n",
      " 12.00   0.00   0.00  77.66%\n",
      "Projected Row:1018 Result:1018 2\n",
      "Projected Row:1018 Result:1019 2\n",
      "Projected Row:1018 Result:1020 2\n",
      "Projected Row:1018 Result:1021 2\n",
      "Projected Row:1018 Result:1022 2\n",
      "Projected Row:1018 Result:1023 2\n",
      "Projected Row:1018 Result:1024 2\n",
      "Projected Row:1018 Result:1025 2\n",
      "Projected Row:1018 Result:1026 2\n",
      "Projected Row:1018 Result:1027 2\n",
      " 13.00   0.00   0.00  79.10%\n",
      "Projected Row:1019 Result:1019 2\n",
      "Projected Row:1019 Result:1020 2\n",
      "Projected Row:1019 Result:1021 2\n",
      "Projected Row:1019 Result:1022 2\n",
      "Projected Row:1019 Result:1023 2\n",
      "Projected Row:1019 Result:1024 2\n",
      "Projected Row:1019 Result:1025 2\n",
      "Projected Row:1019 Result:1026 2\n",
      "Projected Row:1019 Result:1027 2\n",
      "Projected Row:1019 Result:1028 2\n",
      " 11.00   0.00   0.00  80.19%\n",
      "Projected Row:1020 Result:1020 2\n",
      "Projected Row:1020 Result:1021 2\n",
      "Projected Row:1020 Result:1022 2\n",
      "Projected Row:1020 Result:1023 2\n",
      "Projected Row:1020 Result:1024 2\n",
      "Projected Row:1020 Result:1025 2\n",
      "Projected Row:1020 Result:1026 0\n",
      "Projected Row:1020 Result:1027 2\n",
      "Projected Row:1020 Result:1028 2\n",
      "Projected Row:1020 Result:1029 0\n",
      "  9.00   2.00   0.00  80.27%\n",
      "Projected Row:1021 Result:1021 2\n",
      "Projected Row:1021 Result:1022 2\n",
      "Projected Row:1021 Result:1023 2\n",
      "Projected Row:1021 Result:1024 2\n",
      "Projected Row:1021 Result:1025 2\n",
      "Projected Row:1021 Result:1026 2\n",
      "Projected Row:1021 Result:1027 2\n",
      "Projected Row:1021 Result:1028 2\n",
      "Projected Row:1021 Result:1029 2\n",
      "Projected Row:1021 Result:1030 2\n",
      "  9.00   0.00   0.00  81.03%\n",
      "Projected Row:1022 Result:1022 2\n",
      "Projected Row:1022 Result:1023 2\n",
      "Projected Row:1022 Result:1024 2\n",
      "Projected Row:1022 Result:1025 2\n",
      "Projected Row:1022 Result:1026 2\n",
      "Projected Row:1022 Result:1027 2\n",
      "Projected Row:1022 Result:1028 2\n",
      "Projected Row:1022 Result:1029 2\n",
      "Projected Row:1022 Result:1030 2\n",
      "Projected Row:1022 Result:1031 2\n",
      "  7.00   0.00   0.00  81.59%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected Row:1023 Result:1023 2\n",
      "Projected Row:1023 Result:1024 2\n",
      "Projected Row:1023 Result:1025 2\n",
      "Projected Row:1023 Result:1026 2\n",
      "Projected Row:1023 Result:1027 2\n",
      "Projected Row:1023 Result:1028 2\n",
      "Projected Row:1023 Result:1029 2\n",
      "Projected Row:1023 Result:1030 2\n",
      "Projected Row:1023 Result:1031 2\n",
      "Projected Row:1023 Result:1032 2\n",
      "  7.00   0.00   0.00  82.11%\n",
      "Projected Row:1024 Result:1024 2\n",
      "Projected Row:1024 Result:1025 2\n",
      "Projected Row:1024 Result:1026 2\n",
      "Projected Row:1024 Result:1027 2\n",
      "Projected Row:1024 Result:1028 2\n",
      "Projected Row:1024 Result:1029 2\n",
      "Projected Row:1024 Result:1030 2\n",
      "Projected Row:1024 Result:1031 2\n",
      "Projected Row:1024 Result:1032 2\n",
      "Projected Row:1024 Result:1033 2\n",
      "  9.00   0.00   0.00  82.75%\n",
      "Projected Row:1025 Result:1025 2\n",
      "Projected Row:1025 Result:1026 2\n",
      "Projected Row:1025 Result:1027 2\n",
      "Projected Row:1025 Result:1028 2\n",
      "Projected Row:1025 Result:1029 2\n",
      "Projected Row:1025 Result:1030 2\n",
      "Projected Row:1025 Result:1031 2\n",
      "Projected Row:1025 Result:1032 2\n",
      "Projected Row:1025 Result:1033 2\n",
      "Projected Row:1025 Result:1034 2\n",
      "  8.00   0.00   0.00  83.27%\n",
      "Projected Row:1026 Result:1026 2\n",
      "Projected Row:1026 Result:1027 2\n",
      "Projected Row:1026 Result:1028 2\n",
      "Projected Row:1026 Result:1029 2\n",
      "Projected Row:1026 Result:1030 2\n",
      "Projected Row:1026 Result:1031 2\n",
      "Projected Row:1026 Result:1032 2\n",
      "Projected Row:1026 Result:1033 2\n",
      "Projected Row:1026 Result:1034 2\n",
      "Projected Row:1026 Result:1035 2\n",
      " 10.00   0.00   0.00  83.88%\n",
      "Projected Row:1027 Result:1027 2\n",
      "Projected Row:1027 Result:1028 2\n",
      "Projected Row:1027 Result:1029 2\n",
      "Projected Row:1027 Result:1030 2\n",
      "Projected Row:1027 Result:1031 2\n",
      "Projected Row:1027 Result:1032 2\n",
      "Projected Row:1027 Result:1033 2\n",
      "Projected Row:1027 Result:1034 2\n",
      "Projected Row:1027 Result:1035 2\n",
      "Projected Row:1027 Result:1036 2\n",
      "  8.00   0.00   0.00  84.34%\n",
      "Projected Row:1028 Result:1028 2\n",
      "Projected Row:1028 Result:1029 2\n",
      "Projected Row:1028 Result:1030 2\n",
      "Projected Row:1028 Result:1031 2\n",
      "Projected Row:1028 Result:1032 2\n",
      "Projected Row:1028 Result:1033 2\n",
      "Projected Row:1028 Result:1034 2\n",
      "Projected Row:1028 Result:1035 2\n",
      "Projected Row:1028 Result:1036 2\n",
      "Projected Row:1028 Result:1037 2\n",
      "  9.00   0.00   0.00  84.83%\n",
      "Projected Row:1029 Result:1029 2\n",
      "Projected Row:1029 Result:1030 2\n",
      "Projected Row:1029 Result:1031 2\n",
      "Projected Row:1029 Result:1032 2\n",
      "Projected Row:1029 Result:1033 2\n",
      "Projected Row:1029 Result:1034 2\n",
      "Projected Row:1029 Result:1035 2\n",
      "Projected Row:1029 Result:1036 2\n",
      "Projected Row:1029 Result:1037 2\n",
      "Projected Row:1029 Result:1038 2\n",
      " 11.00   0.00   0.00  85.38%\n",
      "Projected Row:1030 Result:1030 2\n",
      "Projected Row:1030 Result:1031 2\n",
      "Projected Row:1030 Result:1032 2\n",
      "Projected Row:1030 Result:1033 2\n",
      "Projected Row:1030 Result:1034 2\n",
      "Projected Row:1030 Result:1035 2\n",
      "Projected Row:1030 Result:1036 2\n",
      "Projected Row:1030 Result:1037 2\n",
      "Projected Row:1030 Result:1038 2\n",
      "Projected Row:1030 Result:1039 2\n",
      " 12.00   0.00   0.00  85.94%\n",
      "Projected Row:1031 Result:1031 2\n",
      "Projected Row:1031 Result:1032 2\n",
      "Projected Row:1031 Result:1033 2\n",
      "Projected Row:1031 Result:1034 2\n",
      "Projected Row:1031 Result:1035 2\n",
      "Projected Row:1031 Result:1036 2\n",
      "Projected Row:1031 Result:1037 2\n",
      "Projected Row:1031 Result:1038 2\n",
      "Projected Row:1031 Result:1039 2\n",
      "Projected Row:1031 Result:1040 2\n",
      " 14.00   0.00   0.00  86.54%\n",
      "Projected Row:1032 Result:1032 2\n",
      "Projected Row:1032 Result:1033 2\n",
      "Projected Row:1032 Result:1034 2\n",
      "Projected Row:1032 Result:1035 2\n",
      "Projected Row:1032 Result:1036 2\n",
      "Projected Row:1032 Result:1037 2\n",
      "Projected Row:1032 Result:1038 2\n",
      "Projected Row:1032 Result:1039 2\n",
      "Projected Row:1032 Result:1040 2\n",
      "Projected Row:1032 Result:1041 2\n",
      " 14.00   0.00   0.00  87.10%\n",
      "Projected Row:1033 Result:1033 2\n",
      "Projected Row:1033 Result:1034 2\n",
      "Projected Row:1033 Result:1035 2\n",
      "Projected Row:1033 Result:1036 2\n",
      "Projected Row:1033 Result:1037 2\n",
      "Projected Row:1033 Result:1038 2\n",
      "Projected Row:1033 Result:1039 2\n",
      "Projected Row:1033 Result:1040 2\n",
      "Projected Row:1033 Result:1041 2\n",
      "Projected Row:1033 Result:1042 2\n",
      " 13.00   0.00   0.00  87.57%\n",
      "Projected Row:1034 Result:1034 2\n",
      "Projected Row:1034 Result:1035 2\n",
      "Projected Row:1034 Result:1036 2\n",
      "Projected Row:1034 Result:1037 2\n",
      "Projected Row:1034 Result:1038 2\n",
      "Projected Row:1034 Result:1039 2\n",
      "Projected Row:1034 Result:1040 2\n",
      "Projected Row:1034 Result:1041 2\n",
      "Projected Row:1034 Result:1042 2\n",
      "Projected Row:1034 Result:1043 2\n",
      " 11.00   0.00   0.00  87.95%\n",
      "Projected Row:1035 Result:1035 2\n",
      "Projected Row:1035 Result:1036 2\n",
      "Projected Row:1035 Result:1037 2\n",
      "Projected Row:1035 Result:1038 2\n",
      "Projected Row:1035 Result:1039 2\n",
      "Projected Row:1035 Result:1040 2\n",
      "Projected Row:1035 Result:1041 2\n",
      "Projected Row:1035 Result:1042 0\n",
      "Projected Row:1035 Result:1043 2\n",
      "Projected Row:1035 Result:1044 2\n",
      " 10.00   1.00   0.00  88.03%\n",
      "Projected Row:1036 Result:1036 2\n",
      "Projected Row:1036 Result:1037 2\n",
      "Projected Row:1036 Result:1038 2\n",
      "Projected Row:1036 Result:1039 2\n",
      "Projected Row:1036 Result:1040 2\n",
      "Projected Row:1036 Result:1041 2\n",
      "Projected Row:1036 Result:1042 2\n",
      "Projected Row:1036 Result:1043 2\n",
      "Projected Row:1036 Result:1044 2\n",
      "Projected Row:1036 Result:1045 2\n",
      "  9.00   0.00   0.00  88.31%\n",
      "Projected Row:1037 Result:1037 2\n",
      "Projected Row:1037 Result:1038 2\n",
      "Projected Row:1037 Result:1039 2\n",
      "Projected Row:1037 Result:1040 2\n",
      "Projected Row:1037 Result:1041 2\n",
      "Projected Row:1037 Result:1042 2\n",
      "Projected Row:1037 Result:1043 2\n",
      "Projected Row:1037 Result:1044 2\n",
      "Projected Row:1037 Result:1045 2\n",
      "Projected Row:1037 Result:1046 2\n",
      "  9.00   0.00   0.00  88.58%\n",
      "Projected Row:1038 Result:1038 2\n",
      "Projected Row:1038 Result:1039 2\n",
      "Projected Row:1038 Result:1040 0\n",
      "Projected Row:1038 Result:1041 2\n",
      "Projected Row:1038 Result:1042 2\n",
      "Projected Row:1038 Result:1043 0\n",
      "Projected Row:1038 Result:1044 2\n",
      "Projected Row:1038 Result:1045 2\n",
      "Projected Row:1038 Result:1046 2\n",
      "Projected Row:1038 Result:1047 2\n",
      "  7.00   2.00   0.00  88.34%\n",
      "Projected Row:1039 Result:1039 2\n",
      "Projected Row:1039 Result:1040 2\n",
      "Projected Row:1039 Result:1041 2\n",
      "Projected Row:1039 Result:1042 2\n",
      "Projected Row:1039 Result:1043 2\n",
      "Projected Row:1039 Result:1044 2\n",
      "Projected Row:1039 Result:1045 2\n",
      "Projected Row:1039 Result:1046 2\n",
      "Projected Row:1039 Result:1047 2\n",
      "Projected Row:1039 Result:1048 2\n",
      "  8.00   0.00   0.00  88.56%\n",
      "Projected Row:1040 Result:1040 2\n",
      "Projected Row:1040 Result:1041 2\n",
      "Projected Row:1040 Result:1042 2\n",
      "Projected Row:1040 Result:1043 2\n",
      "Projected Row:1040 Result:1044 2\n",
      "Projected Row:1040 Result:1045 2\n",
      "Projected Row:1040 Result:1046 2\n",
      "Projected Row:1040 Result:1047 2\n",
      "Projected Row:1040 Result:1048 2\n",
      "Projected Row:1040 Result:1049 2\n",
      "  9.00   0.00   0.00  88.81%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-75befc9f56fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtest_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mopt_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtot_r\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mopt_r\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtot_w\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mopt_w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-118-9e0bccfa9c5c>\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(tries)\u001b[0m\n\u001b[0;32m     87\u001b[0m                       metrics=['accuracy'])  # what to track\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tot_r = tot_w = 0.0\n",
    "opt_r = opt_w = 0.0\n",
    "for projectedRow in range(1000, 2600, 1):\n",
    "    loadData(projectedRow-100, projectedRow-1, projectedRow, projectedRow+10)\n",
    "    model_inputs = normalize(model_inputs)\n",
    "    test_inputs = normalize(test_inputs)\n",
    "    opt_r, opt_w = optimize(1)\n",
    "    tot_r += opt_r\n",
    "    tot_w += opt_w\n",
    "    print( \"{p:6.2f}%\".format(p=100*(tot_r/(tot_r+tot_w))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projectedRow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
